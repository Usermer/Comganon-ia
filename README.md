# ğŸ¤– Compagnon IA - SystÃ¨me RAG Ã‰ducatif

Un assistant IA intelligent basÃ© sur **RAG (Retrieval-Augmented Generation)** qui permet d'interroger des documents PDF et de recommander des ressources d'apprentissage (Wikipedia, YouTube, Coursera, Udemy, FreeCodeCamp).

## âœ¨ FonctionnalitÃ©s

- ğŸ“„ **Analyse de PDF** : Chargez un document PDF et posez des questions dessus
- ğŸ” **RAG Dynamique** : Recherche sÃ©mantique dans les documents avec ChromaDB
- ğŸ¤– **IA Conversationnelle** : GÃ©nÃ©ration de rÃ©ponses via Ollama (Mistral/Orca-Mini)
- ğŸ“š **Recommandation de Modules** : Suggestions de ressources d'apprentissage basÃ©es sur vos questions
- ğŸ¨ **Interface Gradio** : Interface utilisateur intuitive et moderne

## ğŸš€ Technologies

- **LangChain** : Framework RAG
- **ChromaDB** : Base de donnÃ©es vectorielle
- **Ollama** : LLM local (Mistral, Orca-Mini)
- **Gradio** : Interface web
- **Scikit-learn** : SystÃ¨me de recommandation (TF-IDF + Cosine Similarity)
- **PyPDF** : Extraction de texte des PDF

## ğŸ“¦ Installation

### 1. Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/Usermer/Comganon-ia.git
cd Comganon-ia
```

### 2. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 3. Installer Ollama

```bash
# Linux / macOS
curl -fsSL https://ollama.com/install.sh | sh

# Windows : tÃ©lÃ©charger depuis https://ollama.com
```

### 4. TÃ©lÃ©charger les modÃ¨les

```bash
ollama pull mistral
ollama pull orca-mini
ollama pull nomic-embed-text
```

### 5. Lancer Ollama

```bash
ollama serve
```

## ğŸ—ï¸ Structure du Projet

```
Comganon-ia/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py                 # Application Gradio complÃ¨te
â”‚   â”œâ”€â”€ app_simple.py          # Version simplifiÃ©e
â”‚   â”œâ”€â”€ main.py                # SystÃ¨me RAG principal
â”‚   â”œâ”€â”€ llm.py                 # Interface LLM Ollama
â”‚   â”œâ”€â”€ retrieve.py            # RÃ©cupÃ©ration de chunks
â”‚   â”œâ”€â”€ dynamic_rag.py         # RAG dynamique pour PDF
â”‚   â”œâ”€â”€ embeddings_chroma.py   # CrÃ©ation d'index ChromaDB
â”‚   â”œâ”€â”€ ingest.py              # Chargement de documents
â”‚   â”œâ”€â”€ split.py               # Division en chunks
â”‚   â”œâ”€â”€ view_chroma.py         # Visualisation de la base
â”‚   â””â”€â”€ search_chroma.py       # Recherche dans ChromaDB
â”œâ”€â”€ docs/                      # Documents PDF Ã  indexer
â”œâ”€â”€ data/
â”‚   â””â”€â”€ chroma_db/            # Base de donnÃ©es vectorielle
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ PEEKC-Dataset-main/   # Dataset de recommandations
â””â”€â”€ requirements.txt

```

## ğŸ¯ Utilisation

### Mode 1 : Interface Gradio (RecommandÃ©)

```bash
cd src
python app.py
```

AccÃ©dez Ã  l'interface sur `http://localhost:7860`

### Mode 2 : Interface Simple

```bash
cd src
python app_simple.py
```

### Mode 3 : Ligne de commande

```bash
cd src
python main.py
```

## ğŸ”§ Configuration

### Changer le modÃ¨le LLM

Dans `src/llm.py` :

```python
self.llm = OllamaLLM(
    model="mistral",  # ou "orca-mini", "llama2", etc.
    temperature=0.1,
    num_predict=200
)
```

### Ajuster les paramÃ¨tres RAG

Dans `src/split.py` :

```python
splitter = CharacterTextSplitter(
    chunk_size=1000,      # Taille des chunks
    chunk_overlap=200     # Chevauchement
)
```

## ğŸ“š CrÃ©er votre propre index

1. **Placer vos PDF** dans le dossier `docs/`

2. **CrÃ©er l'index ChromaDB** :

```bash
cd src
python embeddings_chroma.py
```

3. **VÃ©rifier l'index** :

```bash
python view_chroma.py
```

4. **Tester la recherche** :

```bash
python search_chroma.py
```

## ğŸ“ Dataset de Recommandations

Le systÃ¨me utilise le **PEEKC Dataset** avec plus de 30 000 ressources :
- Wikipedia
- YouTube
- Coursera
- Udemy
- FreeCodeCamp

## ğŸ› RÃ©solution de ProblÃ¨mes

### Ollama ne rÃ©pond pas

```bash
# VÃ©rifier qu'Ollama tourne
ollama list

# Relancer le serveur
ollama serve
```

### Index ChromaDB vide

```bash
# RecrÃ©er l'index
cd src
python embeddings_chroma.py
```

### Erreur de modÃ¨le manquant

```bash
# TÃ©lÃ©charger le modÃ¨le
ollama pull nomic-embed-text
```

## ğŸ“Š Performances

| OpÃ©ration | Temps moyen |
|-----------|-------------|
| Chargement PDF | ~2-5s |
| Recherche ChromaDB | ~0.5s |
| GÃ©nÃ©ration rÃ©ponse | ~3-10s |
| Recommandations | ~0.2s |

## ğŸ¤ Contribuer

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
- ğŸ› Signaler des bugs
- ğŸ’¡ Proposer de nouvelles fonctionnalitÃ©s
- ğŸ“ AmÃ©liorer la documentation

## ğŸ“„ Licence

MIT License - Voir le fichier LICENSE pour plus de dÃ©tails

## ğŸ™ Remerciements

- [LangChain](https://langchain.com)
- [Ollama](https://ollama.com)
- [ChromaDB](https://www.trychroma.com)
- [Gradio](https://gradio.app)
- [PEEKC Dataset](https://github.com/PEEKC/PEEKC-Dataset)

---

DÃ©veloppÃ© avec â¤ï¸ par [Usermer](https://github.com/Usermer)